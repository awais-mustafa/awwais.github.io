[{"content":"Credentials ğŸ”— Certificate ğŸ”— Score Report ğŸ”— Credly Badge Introduction I\u0026rsquo;ve passed the AWS Solutions Architect - Associate certification exam with a score of 962/1000 with just 2 months of preparation while working full-time as a software engineer. In this article, Iâ€™ll be sharing everything about this exam, my preparation strategies and tips. So, if you have plans on taking this exam anytime soon, read this article till the end.\nWhat is AWS Solutions Architect Associate Certification With the rise of Cloud Computing, companies have constantly been shifting from running their infrastructure on-premise, to running them on cloud, which offers far more elasticity in terms of scaling and resiliency in case a disaster strikes.\nThe AWS Solutions Architect - Associate certification validates your ability to design and deploy well-architected solutions on AWS, which is the leading cloud provider today. In simple terms, this exam tests your ability to propose an architecture given a specific scenario. For example: a company wants their application to continue running even if an entire AWS region, where that application was hosted, is down due to a disaster. So, how would you design their infrastructure around this use case?\nExam Format In this exam, you will get 65 questions and 130 minutes to answer them which means you get 2 mins per question. You will be graded on a percentile basis on a scale of 100 to 1000 where you will nead to score more than 720 to pass the exam. Based on this information, you can approximate that you will have to answer about 72% of the questions correctly in order to pass. You can refer this link for more details on how scoring works.\nThis exam has a pass / fail criteria. If you pass the exam, your score doesn\u0026rsquo;t really matter. It will only be written on your score report for your reference. It will not be mentioned anywhere on the certificate.\nThe cost of taking this exam is 150 USD and with taxes it comes up to about 177 USD. Since I took the exam in India, the amount for me was around 13,500 INR.\nMy Preparation Strategy I prepared for about 2 months while having a full-time job and simultaneously running my ğŸ¬ YouTube channel where I post resourceful videos every week. During these 2 months of preparatory period, I studied for about 2 hours on weekdays and 4-6 hours on weekends.\nFor preparation, I took the AWS Solutions Architect Associate Course by Stephane Maarek which is available on Udemy. While taking this course, I dumped all of the information available in the course into a Notion page.\nOnce I was done with the course, I bought three practice test packages for the AWS SAA exam on Udemy that are provided by:\nStephane Maarek Jon Bonso Neal Davis Each of these practice test packages contain 6 practice tests. Additionally, a free practice test is provided with the course.\nWhile taking the practice tests, I dumped the questions along with their explanations, into a Notion page, for the questions that I got wrong and the questions that I found difficult to answer. This would come in handy later when I revise everything before the exam.\nUntil now, everything was entangled in my head as I had not consumed information in an organized manner. So, I consolidated all of the information from the course and the practice tests into dense concise notes that, instead of Notion, I took on another note-taking app called Obsidian. Iâ€™ll explain why in another video. For the sake of the AWS exam, you can take your notes anywhere.\nIf you want my notes, you will have to wait for some time until I figure out a way to share my Obsidian notes in a presentable format. They cannot be directly shared like Notion pages.\nConsolidating my notes took about a week and while doing so I went through all of the information again but this time with a much more idea of the concepts. Everything started making sense and I felt confident to take the AWS SAA exam. So, I revised my consolidated notes once and took the exam the next day.\nTaking the Test You can either take the test offline at a testing center or online at the comfort of your home. I would suggest you take the test offline if you have testing centers in your area. If not, then you can take the online route. I had to take this test online as there are no testing centers nearby.\nDo keep in mind that the proctoring in the online test is extremely strict and if the proctor cancels your exam, you won\u0026rsquo;t get a refund. In such a scenario, you will have to rebook and retake the test at a later date.\nTips for taking the AWS SAA exam Take as many practice tests as you can. They will give you an idea of the kind of topics that come up in the exam most often. Also, the questions in these practice tests match very well with the ones appearing on the actual exam.\nThe amount of information that you will have to go through to prepare for this exam is enormous. You not only need a good understanding of the various AWS resources and architectures, but you will also have to remember a lot of information. So, filtering out the irrelevant details from the dumped information and making concise notes, that you can easily revise within 1 or 2 days is crucial for this exam.\nThat\u0026rsquo;s all folks That was all about the AWS Solutions Architect - Associate exam. Up next, I have plans to take the AWS Developer Associate exam which focuses on the development aroud AWS services. As a personal milestone, I want to clear the AWS Developer Associate exam before I move to Canada ğŸ‡¨ğŸ‡¦ for my MS.\n","permalink":"https://awwais.me/playbook/blog/aws-saa-certification/","summary":"Credentials ğŸ”— Certificate ğŸ”— Score Report ğŸ”— Credly Badge Introduction I\u0026rsquo;ve passed the AWS Solutions Architect - Associate certification exam with a score of 962/1000 with just 2 months of preparation while working full-time as a software engineer. In this article, Iâ€™ll be sharing everything about this exam, my preparation strategies and tips. So, if you have plans on taking this exam anytime soon, read this article till the end.","title":"I passed the AWS SAA Certification Exam"},{"content":"Introduction to machine learning In the traditional hard-coded approach, we program a computer to perform a certain task. We tell it exactly what to do when it receives a certain input. In mathematical terms, this is like saying that we write theÂ f(x)Â such that when users feed the inputÂ xÂ intoÂ f(x), it gives the correct outputÂ y.\nIn machine learning, however, we have a large set of inputs x and corresponding outputs y but not the function f(x). The goal here is to find the f(x) that transforms the input x into the output y. Well, thatâ€™s not an easy job. In this article, we will learn how this happens.\nDataset To visualize the dataset, letâ€™s make our synthetic dataset where each data point (inputÂ x) is 3 dimensional, making it suitable to be plotted on a 3D chart. We will generate 250 pointsÂ (cluster 0)Â in a cluster centered at the origin (0, 0, 0). A similar cluster of 250 pointsÂ (cluster 1)Â is generated but not centered at the origin. Both clusters are relatively close but there is a clear separation as seen in the image below. These two clusters are the two classes of data points. The big green dot represents the centroid of the whole dataset.\nAfter generating the dataset, we will normalize it by subtracting the mean and dividing by the standard deviation. This is done to zero-center the data and map values in each dimension in the dataset to a common scale. This speeds up the learning.\nThe data will be saved in an array X containing the 3D coordinates of normalized points. We will also generate an array Y with the value either 0 or 1 at each index depending on which cluster the 3D point belongs.\nLearnable Function Now that we have our data ready, we can say that we have theÂ xÂ andÂ y.Â We know that the dataset is linearly separable implying that there is a plane that can divide the dataset into the two clusters, but we donâ€™t know what the equation of such an optimal plane is. For now, letâ€™s just take a random plane.\nThe function f(x) should take a 3D coordinate as input and output a number between 0 and 1. If this number is less than 0.5, this point belongs to cluster 0 otherwise, it belongs to cluster 1. Letâ€™s define a simple function for this task.\nx: input tensor of shape (num_points, 3)W: Weight (parameter) of shape (3, 1) chosen randomlyB: Bias (parameter) of shape (1, 1) chosen randomlySigmoid: A function that maps values between 0 and 1\nLetâ€™s take a moment to understand what this function means.Â Before applying the sigmoid function, we are simply creating a linear mapping from the 3D coordinate (input) to 1D output. Therefore,Â this function will squish the whole 3D space onto a lineÂ meaning that each point in the original 3D space will now be lying somewhere on this line.Â Since this line will extend to infinity,Â we map it toÂ [0, 1]Â using theÂ SigmoidÂ function. As a result, for each given input,Â f(x)Â will output a value between 0 and 1.\nRemember that W and B are chosen randomly and so the 3D space will be squished onto a random line. The decision boundary for this transformation is the set of points that makeÂ f(x)Â = 0.5. Think why! As the 3D space is being squished onto a 1D line, a whole plane is mapped to the value 0.5 on the line. This plane is the decision boundary for f(x). Ideally, it should divide the dataset into two clusters butÂ sinceÂ WÂ andÂ BÂ are randomly chosen, this plane is randomly oriented as shown below.\nOur goal is to find the right values for W and B that orients this plane (decision boundary) in such a way that it divides the dataset into the two clusters. This when done, yields a plane as shown below.\nLoss So, we are now at the starting point (random decision boundary) and we have defined the goal. We need a metric to decide how far we are from the goal. The output of the classifier is a tensor of shape (num_points, 1) where each value is betweenÂ [0, 1]. If you think carefully, these values are just the probabilities of the points belonging to cluster 1. So, we can say that:\nf(x) = P(x belongs to cluster 1) 1-f(x) = P(x belongs to cluster 0) It wouldnâ€™t be wrong to say that [1-f(x), f(x)] forms a probability distribution over the clusters 0 and cluster 1 respectively. This is theÂ predicted probability distribution. We know for sure which cluster every point in the dataset belongs to (fromÂ y). So, we also have theÂ true probability distributionÂ as:\n[0, 1] when x belongs to the cluster 1 [1, 0] when x belongs to the cluster 0 A good metric to calculate the incongruity between two probability distributions is theÂ Cross-EntropyÂ function. As we are dealing with just 2 classes, we can useÂ Binary Cross-Entropy (BCE).Â This function is available in PyTorchâ€™sÂ torch.nnÂ module. If the predicted probability distribution is very similar to the true probability distribution, this function returns a small value and vice versa. We can average this value for all the data points and use it as a parameter to test how the classifier is performing.\nThis value is called the loss and mathematically, our goal now is to minimize this loss.\nTraining Now that we have defined our goal mathematically, how do we reach our goal practically? In other words, how do we find optimal values forÂ WÂ andÂ B? To understand this, we will take a look at some basic calculus. Recall that we currently have random values forÂ WÂ andÂ B.Â The process of learning or training or reaching the goal or minimizing the loss can be divided into two steps:\nForward-propagation: We feed the dataset through the classifier f(x) and use BCE to find the loss. Backpropagation: Using the loss, adjust the values of W and B to minimize the loss. The above two steps will be repeated over and over again until the loss stops decreasing. In this condition, we say that we have reached the goal!\nBackpropagation Forward propagation is simple and already discussed above. However, it is essential to take a moment to understandÂ backpropagationÂ as it is the key to machine learning. Recall that we have 3 parameters (variables) inÂ WÂ and 1 inÂ B. So, in total, we have 4 values to optimize.\nOnce we have the loss from forward-propagation, we will calculate the gradients of the loss function with respect to each variable in the classifier. If we plot the loss for different values of each parameter, we can see that the loss is minimum at a particular value for each parameter. I have plotted the loss vs parameter for each parameter.\nAn important observation to make here is that the loss is minimized at a particular value for each of these parameters as shown by the red dot.\nLetâ€™s consider the first plot and discuss how w1 will be optimized. The process remains the same for the other parameters. Initially, the values for W and B are chosen randomly and soÂ (w1, loss)Â will be randomly placed on this curve as shown by the green dot.\nNow, the goal is to reach the red dot, starting from the green dot. In other words, we need to move downhill. Looking at the slope of the curve at the green dot, we can tell that increasing w1 (moving right) will lower the loss and therefore move the green dot closer to the red one. In mathematical terms, if the gradient of the loss with respect to w1 is negative, increase w1 to move downhill and vice versa. Therefore, w1 should be updated as:\nThe equation above is known asÂ gradient descent equation. Here, theÂ learning_rateÂ controls how much we want to increase or decrease w1. If the learning_rate is large, the update will be large. This could lead to w1 going past the red dot and therefore missing the optimal value. If this value is too small, it will take forever for w1 to reach the red dot. You can try experimenting with different values of learning rate to see which works the best. In general, small values likeÂ 0.01Â works well for most cases.\nIn most cases, a single update is not enough to optimize these parameters; so, the process of forward-propagation and backpropagation is repeated in a loop until the loss stops reducing further. Letâ€™s see this in action:\nAn important observation to make is that initially the green dot moves quickly and slows down as it gradually approaches the minima. The large slope (gradient) during the first few epochs (when the green dot is far from the minima) is responsible for this large update to the parameters. The gradient decreases as the green dot approaches the minima and thus the update becomes slow. The other three parameters are trained in parallel in the exact same way. Another important observation is that the shape of the curve changes with epoch. This is due to the fact that the other three parameters (w2, w3, b) are also being updated in parallel and each parameter contributes to the shape of the loss curve.\nVisualize Letâ€™s see how the decision boundary updates in real-time as the parameters are being updated.\nThatâ€™s all folks! If you made it till here, hats off to you! In this article, we took a visual approach to understand how machine learning works. So far, we have seen how a simple 3D to 1D mapping,Â f(x), can be used to fit a decision boundary (2D plane) to a linearly separable dataset (3D). We discussed how forward propagation is used to calculate the loss followed by backpropagation where gradients of the loss with respect to parameters are calculated and the parameters are updated repeatedly in a training loop.\n","permalink":"https://awwais.me/playbook/blog/machine-learning-visualized/","summary":"Introduction to machine learning In the traditional hard-coded approach, we program a computer to perform a certain task. We tell it exactly what to do when it receives a certain input. In mathematical terms, this is like saying that we write theÂ f(x)Â such that when users feed the inputÂ xÂ intoÂ f(x), it gives the correct outputÂ y.\nIn machine learning, however, we have a large set of inputs x and corresponding outputs y but not the function f(x).","title":"Machine Learning - Visualized"},{"content":"Simon Game â™¦ PLAY IT NOW ğŸ­ âš¡Follow the pattern of lights for as long as you can\u0026hellip; if you can! that\u0026rsquo;s it Now let get Started\n#### You Can't Play This Game On Mobile Devices Code ğŸ‘¨â€ğŸ’» SimonGameCode\n","permalink":"https://awwais.me/playbook/projects/simongame/","summary":"Simon Game â™¦ PLAY IT NOW ğŸ­ âš¡Follow the pattern of lights for as long as you can\u0026hellip; if you can! that\u0026rsquo;s it Now let get Started\n#### You Can't Play This Game On Mobile Devices Code ğŸ‘¨â€ğŸ’» SimonGameCode","title":"SimonGame"},{"content":"âš” I Make Simple 2D Game Using Unity. ğŸ—¯ ğŸ”— PlayItNow ğŸ”— GitHub Description A web application game built using Unity Engine that allows the user to Play, and Enjoy the game in their browser.Its Webgl game. I built this app while learning Unity.\n","permalink":"https://awwais.me/playbook/projects/unityproject/","summary":"âš” I Make Simple 2D Game Using Unity. ğŸ—¯ ğŸ”— PlayItNow ğŸ”— GitHub Description A web application game built using Unity Engine that allows the user to Play, and Enjoy the game in their browser.Its Webgl game. I built this app while learning Unity.","title":"SnowBorder Game"},{"content":" ğŸ”— View Website ğŸ”— GitHub Description A simple website built using Html,Css,javascript and Bootstrap. I built this app while learning BootStrap.\n","permalink":"https://awwais.me/playbook/projects/tindog/","summary":"ğŸ”— View Website ğŸ”— GitHub Description A simple website built using Html,Css,javascript and Bootstrap. I built this app while learning BootStrap.","title":"TinDog Website"},{"content":"ğŸ”— View App ğŸ”— GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.\n","permalink":"https://awwais.me/playbook/projects/todo-list-app/","summary":"ğŸ”— View App ğŸ”— GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.","title":"Todo List App"},{"content":" ğŸ”— Code Description Its Simple App When you open this App: ğŸš€ Firstly loaded an image of meme by calling a open source API. ğŸš€ When image comes from API then it extract them into volley library, then show in screen with the help of Glide Library.That\u0026rsquo;s it.ğŸ•¸ When you Click on Next its loaded a new meme. ğŸ•¸ And when you Click on Share() button its called your operating System Share functionality and shows share option.\n","permalink":"https://awwais.me/playbook/projects/memeapp/","summary":"ğŸ”— Code Description Its Simple App When you open this App: ğŸš€ Firstly loaded an image of meme by calling a open source API. ğŸš€ When image comes from API then it extract them into volley library, then show in screen with the help of Glide Library.That\u0026rsquo;s it.ğŸ•¸ When you Click on Next its loaded a new meme. ğŸ•¸ And when you Click on Share() button its called your operating System Share functionality and shows share option.","title":"Meme App"},{"content":"again and again\n","permalink":"https://awwais.me/playbook/docs/test2/","summary":"again and again","title":"Test"}]